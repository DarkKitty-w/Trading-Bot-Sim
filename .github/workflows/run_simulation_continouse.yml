name: Run Crypto Simulator - Continuous

on:
  workflow_dispatch:
    inputs:
      total_duration_hours:
        description: 'Total desired simulation time in hours (e.g., 48)'
        required: true
        default: '24'
      elapsed_duration_hours:
        description: 'Internal: Time already elapsed (DO NOT set manually)'
        required: false
        default: '0'
      debug_skip_first_run:
        description: 'DEBUG: Skip simulation and trigger next run immediately'
        required: true
        default: 'false'
      debug_start_from_hour:
        description: 'DEBUG: Start from specific hour (overrides elapsed_duration_hours)'
        required: false
        default: '0'

jobs:
  run-simulation-10:
    runs-on: ubuntu-latest
    timeout-minutes: 320
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      # --- DEBUG: SKIP SIMULATION IF REQUESTED ---
      - name: Debug - Skip simulation run
        if: inputs.debug_skip_first_run == 'true'
        run: |
          echo "⚠️ DEBUG MODE: Skipping simulation execution"
          echo "This run will only download existing artifacts and trigger next run"
          echo "Starting from hour: ${{ inputs.debug_start_from_hour }}"

      - name: Install dependencies
        if: inputs.debug_skip_first_run == 'false'
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy matplotlib requests seaborn plotly scipy

      # --- 1. PREPARE DIRECTORIES ---
      - name: Create output directories
        run: |
          mkdir -p portfolio_logs_10/charts
          mkdir -p full_results/logs
          mkdir -p full_results/json
          mkdir -p full_results/csv
          mkdir -p full_results/charts-png
          mkdir -p full_results/charts-html
          mkdir -p full_results/stdout

      # --- 2. DOWNLOAD PREVIOUS STATE & RESULTS ---
      - name: Download PREVIOUS state - 10$
        uses: actions/download-artifact@v4
        with:
          name: simulation-state-10
          path: portfolio_logs_10/
        continue-on-error: true

      - name: Download PREVIOUS full results - 10$
        uses: actions/download-artifact@v4
        with:
          name: full-results-10
          path: full_results/
        continue-on-error: true
      
      # --- 3. RUN SIMULATION CHUNK (SKIPPED IN DEBUG MODE) ---
      - name: Run 10$ simulation (5 hour chunk)
        if: inputs.debug_skip_first_run == 'false'
        run: |
          python simulator_continuise.py 10 | tee full_results/stdout/simulation_stdout_${{ inputs.elapsed_duration_hours }}h.txt
        
      # --- 4. AGGREGATE RESULTS (SKIPPED IN DEBUG MODE) ---
      - name: Aggregate and prepare results - 10$
        if: inputs.debug_skip_first_run == 'false'
        run: |
          echo "Aggregating results for run at ${{ inputs.elapsed_duration_hours }}h"
          
          # 1. Log Aggregation
          if [ -f "portfolio_logs_10/enhanced_simulation.log" ]; then
            cat portfolio_logs_10/enhanced_simulation.log >> full_results/logs/main-log-full.log
          fi
          
          # 2. JSON Aggregation (JSON Lines)
          if [ -f "portfolio_logs_10/summary_results.json" ]; then
            cat portfolio_logs_10/summary_results.json >> full_results/json/summary-results-full.jsonl
          fi
          
          # 3. CSV Aggregation
          CSV_FILE="portfolio_logs_10/trade_log_10.csv" 
          ALL_CSV_PATH="full_results/csv/trade_log_all.csv"
          
          if [ -f "$CSV_FILE" ]; then
            if [ ! -f $ALL_CSV_PATH ]; then
               echo "Creating initial full CSV file."
               cp $CSV_FILE $ALL_CSV_PATH
            else
               echo "Appending new trade logs (skipping header)."
               tail -n +2 $CSV_FILE >> $ALL_CSV_PATH
            fi
          fi
          
          # 4. Chart Aggregation
          RUN_ID="run_${{ inputs.elapsed_duration_hours }}h"
          
          for f in portfolio_logs_10/charts/*.png; do 
            if [ -f "$f" ]; then 
              cp "$f" "full_results/charts-png/$(basename "$f" .png)_${RUN_ID}.png"; 
            fi
          done
          
          for f in portfolio_logs_10/charts/*.html; do 
            if [ -f "$f" ]; then 
              cp "$f" "full_results/charts-html/$(basename "$f" .html)_${RUN_ID}.html"; 
            fi
          done

      # --- DEBUG: SIMULATE SUCCESSFUL RUN ---
      - name: Debug - Create dummy state file
        if: inputs.debug_skip_first_run == 'true'
        run: |
          echo "Creating dummy state file for debug continuation..."
          echo '{"debug_mode": true, "elapsed_hours": "${{ inputs.debug_start_from_hour }}", "timestamp": "'$(date)'"}' > portfolio_logs_10/simulation_state.json
          
      # --- 5. UPLOAD NEW STATE & AGGREGATED RESULTS ---
      - name: Upload CURRENT state - 10$
        uses: actions/upload-artifact@v4
        with:
          name: simulation-state-10
          path: portfolio_logs_10/simulation_state.json
          retention-days: 7

      - name: Upload FULL aggregated results - 10$
        if: inputs.debug_skip_first_run == 'false'
        uses: actions/upload-artifact@v4
        with:
          name: full-results-10
          path: full_results/
          retention-days: 30

      # --- 6. LOOPING LOGIC ---
      - name: Calculate next run
        id: calc
        run: |
          RUN_CHUNK_HOURS=5
          
          # Use debug start hour if provided, otherwise use elapsed_duration_hours
          if [ "${{ inputs.debug_start_from_hour }}" != "0" ]; then
            ELAPSED=${{ inputs.debug_start_from_hour }}
            echo "Using debug start hour: $ELAPSED"
          else
            ELAPSED=${{ inputs.elapsed_duration_hours }}
          fi
          
          TOTAL=${{ inputs.total_duration_hours }}
          NEW_ELAPSED=$(($ELAPSED + $RUN_CHUNK_HOURS))
          echo "Total duration: $TOTAL hours, Time after this run: $NEW_ELAPSED hours"
          if [ $NEW_ELAPSED -lt $TOTAL ]; then
            echo "CONTINUE=true" >> $GITHUB_OUTPUT
            echo "NEW_ELAPSED=$NEW_ELAPSED" >> $GITHUB_OUTPUT
          else
            echo "CONTINUE=false" >> $GITHUB_OUTPUT
            echo "--- SIMULATION COMPLETE ---"
          fi

      - name: Get workflow ID and trigger next run
        if: steps.calc.outputs.CONTINUE == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_PAT }}
        run: |
          echo "Triggering next run, elapsed time will be: ${{ steps.calc.outputs.NEW_ELAPSED }} hours..."
          
          # Install jq for JSON parsing
          sudo apt-get update && sudo apt-get install -y jq curl
          
          # Get all workflows and find the specific one by name
          echo "Getting workflow ID for: run_simulation_continouse.yml"
          WORKFLOW_RESPONSE=$(curl -s -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows")
          
          echo "Workflows response:"
          echo "$WORKFLOW_RESPONSE" | jq .
          
          # Extract the workflow ID for our specific workflow file
          WORKFLOW_ID=$(echo "$WORKFLOW_RESPONSE" | jq -r '.workflows[] | select(.path == ".github/workflows/run_simulation_continouse.yml") | .id')
          
          if [ -z "$WORKFLOW_ID" ] || [ "$WORKFLOW_ID" = "null" ]; then
            echo "ERROR: Could not find workflow ID for run_simulation_continouse.yml"
            echo "Available workflows:"
            echo "$WORKFLOW_RESPONSE" | jq -r '.workflows[] | "\(.name) - \(.path) - \(.id)"'
            exit 1
          fi
          
          echo "Found workflow ID: $WORKFLOW_ID"
          
          # Trigger the workflow using the ID
          echo "Triggering workflow dispatch..."
          TRIGGER_RESPONSE=$(curl -X POST \
            -H "Authorization: token $GH_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/actions/workflows/$WORKFLOW_ID/dispatches" \
            -d "{
              \"ref\": \"${{ github.ref }}\",
              \"inputs\": {
                \"total_duration_hours\": \"${{ inputs.total_duration_hours }}\",
                \"elapsed_duration_hours\": \"${{ steps.calc.outputs.NEW_ELAPSED }}\",
                \"debug_skip_first_run\": \"false\",
                \"debug_start_from_hour\": \"0\"
              }
            }")
          
          echo "Trigger response: $TRIGGER_RESPONSE"
          
          if [ -z "$TRIGGER_RESPONSE" ]; then
            echo "✅ Successfully triggered next workflow run!"
          else
            echo "Trigger response: $TRIGGER_RESPONSE"
          fi
            
      - name: Final Run Complete
        if: steps.calc.outputs.CONTINUE == 'false'
        run: |
          echo "This was the final run."
          echo "The artifact 'full-results-10' now contains all aggregated data."
